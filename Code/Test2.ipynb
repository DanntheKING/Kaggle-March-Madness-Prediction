{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import log_loss, mean_absolute_error, brier_score_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "import joblib\n",
    "import xgboost as xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/app/MarchMadness/Kaggle-March-Madness-Prediction/Data/march-machine-learning-mania-2025'\n",
    "\n",
    "# Check if the path exists\n",
    "print(\"Checking data path:\", os.path.exists(DATA_PATH))\n",
    "\n",
    "# List all files in the directory\n",
    "files = glob.glob(os.path.join(DATA_PATH, \"*.csv\"))\n",
    "print(\"Files found:\", files)\n",
    "print(files)\n",
    "\n",
    "# Attempt to load one file explicitly\n",
    "if files:\n",
    "    test_file = files[0]\n",
    "    print(f\"Attempting to load {test_file}\")\n",
    "    try:\n",
    "        df = pd.read_csv(test_file)\n",
    "        print(df.head())  # Print first few rows\n",
    "    except Exception as e:\n",
    "        print(\"Error loading file:\", e)\n",
    "else:\n",
    "    print(\"No files found in the dataset directory!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    files = glob.glob(os.path.join(data_path, \"*.csv\"))\n",
    "    files = [f for f in files if os.path.isfile(f)]  # Filter out directories\n",
    "    data = {p.split('/')[-1].split('.')[0]: pd.read_csv(p, encoding='latin-1') for p in files}\n",
    "    return data\n",
    "\n",
    "#data = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    # Combine men's and women's data\n",
    "    teams = pd.concat([data['MTeams'], data['WTeams']])\n",
    "    teams_spelling = pd.concat([data['MTeamSpellings'], data['WTeamSpellings']])\n",
    "    teams_spelling = teams_spelling.groupby(by='TeamID', as_index=False)['TeamNameSpelling'].count()\n",
    "    teams_spelling.columns = ['TeamID', 'TeamNameCount']\n",
    "    teams = pd.merge(teams, teams_spelling, how='left', on=['TeamID'])\n",
    "    del teams_spelling\n",
    "\n",
    "    # Combine regular season and tournament results\n",
    "    season_cresults = pd.concat([data['MRegularSeasonCompactResults'], data['WRegularSeasonCompactResults']])\n",
    "    season_dresults = pd.concat([data['MRegularSeasonDetailedResults'], data['WRegularSeasonDetailedResults']])\n",
    "    tourney_cresults = pd.concat([data['MNCAATourneyCompactResults'], data['WNCAATourneyCompactResults']])\n",
    "    tourney_dresults = pd.concat([data['MNCAATourneyDetailedResults'], data['WNCAATourneyDetailedResults']])\n",
    "\n",
    "    # Process seeds\n",
    "    seeds_df = pd.concat([data['MNCAATourneySeeds'], data['WNCAATourneySeeds']])\n",
    "    seeds = {\n",
    "        '_'.join(map(str, [int(k1), k2])): int(v[1:3])\n",
    "        for k1, v, k2 in seeds_df[['Season', 'Seed', 'TeamID']].values\n",
    "    }\n",
    "\n",
    "    # Load submission file\n",
    "    sub = data['SampleSubmissionStage2']  # Load the correct sample submission file\n",
    "    del seeds_df\n",
    "\n",
    "    # Combine all games and preprocess\n",
    "    season_cresults['ST'] = 'S'\n",
    "    season_dresults['ST'] = 'S'\n",
    "    tourney_cresults['ST'] = 'T'\n",
    "    tourney_dresults['ST'] = 'T'\n",
    "\n",
    "    games = pd.concat((season_dresults, tourney_dresults), axis=0, ignore_index=True)\n",
    "    games.reset_index(drop=True, inplace=True)\n",
    "    games['WLoc'] = games['WLoc'].map({'A': 1, 'H': 2, 'N': 3})\n",
    "\n",
    "    # Create unique IDs for games and teams\n",
    "    games['ID'] = games.apply(\n",
    "        lambda r: '_'.join(map(str, [r['Season']] + sorted([r['WTeamID'], r['LTeamID']]))), axis=1\n",
    "    )\n",
    "    games['IDTeams'] = games.apply(\n",
    "        lambda r: '_'.join(map(str, sorted([r['WTeamID'], r['LTeamID']])))\n",
    "    , axis=1)\n",
    "    games['Team1'] = games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[0], axis=1)\n",
    "    games['Team2'] = games.apply(lambda r: sorted([r['WTeamID'], r['LTeamID']])[1], axis=1)\n",
    "    games['IDTeam1'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team1']])), axis=1)\n",
    "    games['IDTeam2'] = games.apply(lambda r: '_'.join(map(str, [r['Season'], r['Team2']])), axis=1)\n",
    "    games['Team1Seed'] = games['IDTeam1'].map(seeds).fillna(0)\n",
    "    games['Team2Seed'] = games['IDTeam2'].map(seeds).fillna(0)\n",
    "\n",
    "    # Calculate win percentage for each team\n",
    "    win_counts = season_cresults.groupby(['Season', 'WTeamID']).size().reset_index(name='Wins')\n",
    "    game_counts = season_cresults.groupby(['Season']).agg({'WTeamID': 'count', 'LTeamID': 'count'}).reset_index()\n",
    "    game_counts['TotalGames'] = game_counts['WTeamID'] + game_counts['LTeamID']\n",
    "    game_counts = game_counts[['Season', 'TotalGames']]\n",
    "\n",
    "    win_percentage = win_counts.merge(game_counts, on='Season', how='left')\n",
    "    win_percentage['WinPct'] = win_percentage['Wins'] / win_percentage['TotalGames']\n",
    "\n",
    "    # Merge win percentage into the dataset\n",
    "    win_pct_dict = win_percentage.set_index(['Season', 'WTeamID'])['WinPct'].to_dict()\n",
    "    games['Team1WinPct'] = games.apply(lambda r: win_pct_dict.get((r['Season'], r['Team1']), -1), axis=1)\n",
    "    games['Team2WinPct'] = games.apply(lambda r: win_pct_dict.get((r['Season'], r['Team2']), -1), axis=1)\n",
    "    games['WinPctDiff'] = games['Team1WinPct'] - games['Team2WinPct']\n",
    "    \n",
    "    # Calculate additional features\n",
    "    games['ScoreDiff'] = games['WScore'] - games['LScore']\n",
    "    games['Pred'] = games.apply(\n",
    "        lambda r: 1.0 if sorted([r['WTeamID'], r['LTeamID']])[0] == r['WTeamID'] else 0.0, axis=1\n",
    "    )\n",
    "    games['ScoreDiffNorm'] = games.apply(\n",
    "        lambda r: r['ScoreDiff'] * -1 if r['Pred'] == 0.0 else r['ScoreDiff'], axis=1)\n",
    "    games['SeedDiff'] = games['Team1Seed'] - games['Team2Seed']\n",
    "    games = games.fillna(-1)\n",
    "\n",
    "    # Aggregate statistics\n",
    "    c_score_col = [\n",
    "        'NumOT', 'WFGM', 'WFGA', 'WFGM3', 'WFGA3', 'WFTM', 'WFTA', 'WOR', 'WDR', 'WAst',\n",
    "        'WTO', 'WStl', 'WBlk', 'WPF', 'LFGM', 'LFGA', 'LFGM3', 'LFGA3', 'LFTM', 'LFTA',\n",
    "        'LOR', 'LDR', 'LAst', 'LTO', 'LStl', 'LBlk', 'LPF'\n",
    "    ]\n",
    "    c_score_agg = ['sum', 'mean', 'median', 'max', 'min', 'std', 'skew', 'nunique']\n",
    "    gb = games.groupby(\"IDTeams\").agg({k: c_score_agg for k in c_score_col}).reset_index()\n",
    "    gb.columns = [\"\".join(c) + \"_c_score\" for c in gb.columns]\n",
    "    \n",
    "    # Filter tournament games\n",
    "    games = games[games[\"ST\"] == \"T\"]\n",
    "\n",
    "    # Preprocess submission data\n",
    "    sub[\"WLoc\"] = 3\n",
    "    sub[\"Season\"] = sub[\"ID\"].map(lambda x: x.split(\"_\")[0]).astype(int)\n",
    "    sub[\"Team1\"] = sub[\"ID\"].map(lambda x: x.split(\"_\")[1])\n",
    "    sub[\"Team2\"] = sub[\"ID\"].map(lambda x: x.split(\"_\")[2])\n",
    "    sub[\"IDTeams\"] = sub.apply(\n",
    "        lambda r: \"_\".join(map(str, [r[\"Team1\"], r[\"Team2\"]])), axis=1)\n",
    "    sub[\"IDTeam1\"] = sub.apply(\n",
    "        lambda r: \"_\".join(map(str, [r[\"Season\"], r[\"Team1\"]])), axis=1)\n",
    "    sub[\"IDTeam2\"] = sub.apply(\n",
    "        lambda r: \"_\".join(map(str, [r[\"Season\"], r[\"Team2\"]])), axis=1)\n",
    "    sub[\"Team1Seed\"] = sub[\"IDTeam1\"].map(seeds).fillna(0)\n",
    "    sub[\"Team2Seed\"] = sub[\"IDTeam2\"].map(seeds).fillna(0)\n",
    "    sub[\"SeedDiff\"] = sub[\"Team1Seed\"] - sub[\"Team2Seed\"]\n",
    "    sub = sub.fillna(-1)\n",
    "\n",
    "    # Merge aggregated stats with games and submission data\n",
    "    games = pd.merge(games, gb, how=\"left\", left_on=\"IDTeams\", right_on=\"IDTeams_c_score\")\n",
    "    sub = pd.merge(sub, gb, how=\"left\", left_on=\"IDTeams\", right_on=\"IDTeams_c_score\")\n",
    "    sub = pd.merge(sub, games[['IDTeams', 'Team1WinPct', 'Team2WinPct', 'WinPctDiff']], how='left', left_on='IDTeams', right_on='IDTeams')\n",
    "    # Remove duplicates based on 'ID'\n",
    "    sub = sub.drop_duplicates(subset=[\"ID\"])\n",
    "\n",
    "    # Define feature columns\n",
    "    exclude_cols = [\n",
    "        \"ID\", \"DayNum\", \"ST\", \"Team1\", \"Team2\", \"IDTeams\", \"IDTeam1\", \"IDTeam2\",\n",
    "        \"WTeamID\", \"WScore\", \"LTeamID\", \"LScore\", \"NumOT\", \"Pred\", \"ScoreDiff\",\n",
    "        \"ScoreDiffNorm\", \"WLoc\"\n",
    "    ] + c_score_col\n",
    "    col = [c for c in games.columns if c not in exclude_cols]\n",
    "\n",
    "    print(\"Data preprocessing completed.\")\n",
    "    return games, sub, col, seeds, gb\n",
    "\n",
    "#games, sub, col, seeds, gb = preprocess_data(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(games, col):\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    X = games[col].fillna(-1)\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    y = games[\"Pred\"]\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        nthread=4,\n",
    "        scale_pos_weight=1,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_scaled, y)\n",
    "    pred = model.predict_proba(X_scaled)[:, 1].clip(0.5, 0.95)\n",
    "    ir = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    ir.fit(pred, y)\n",
    "    pred_cal = ir.transform(pred)\n",
    "\n",
    "    print(f\"Log Loss: {log_loss(y, pred_cal):.8f}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y, pred_cal):.8f}\")\n",
    "    print(f\"Brier Score: {brier_score_loss(y, pred_cal):.8f}\")\n",
    "    cv_scores = cross_val_score(model, X_scaled, y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    print(f\"Cross-validated MSE: {-cv_scores.mean():.8f}\")\n",
    "\n",
    "    return model, imputer, scaler, ir\n",
    "\n",
    "#model, imputer, scaler, ir = train_model(games, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_submission(sub, col, model, imputer, scaler, ir, games, output_file=\"/app/MarchMadness/Kaggle-March-Madness-Prediction/SubmissionPredictions/submission.csv\"):\n",
    "    \n",
    "    # Proceed with prediction\n",
    "    sub_X = sub[col].fillna(-1)\n",
    "    X_imputed = imputer.transform(sub_X)\n",
    "    X_scaled = scaler.transform(X_imputed)\n",
    "    preds = model.predict_proba(X_scaled)[:, 1].clip(0.5, 0.95)\n",
    "    preds_cal = ir.transform(preds)\n",
    "    sub[\"Pred\"] = preds_cal\n",
    "    \n",
    "    # Save the submission file\n",
    "    sub[[\"ID\", \"Pred\"]].to_csv(output_file, index=False)\n",
    "    print(f\"Submission file saved to {output_file}\")\n",
    "\n",
    "\n",
    "#predict_submission(sub, col, model, imputer, scaler, ir, games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, imputer, scaler, seeds, col, gb, ir, filename):\n",
    "    joblib.dump({\n",
    "        \"model\": model,\n",
    "        \"scaler\": scaler,\n",
    "        \"imputer\": imputer,\n",
    "        \"seeds\": seeds,\n",
    "        \"col\": col,\n",
    "        \"gb\": gb,\n",
    "        \"ir\": ir\n",
    "    }, filename)\n",
    "    print(f\"Model saved to {filename}\")\n",
    "\n",
    "#save_model(model, imputer, scaler, seeds, col, gb, ir, \"/app/MarchMadness/Kaggle-March-Madness-Prediction/ModelPath/tournament_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = load_data(DATA_PATH)\n",
    "    games, sub, col, seeds, gb = preprocess_data(data)\n",
    "    model, imputer, scaler, ir = train_model(games, col)\n",
    "    predict_submission(sub, col, model, imputer, scaler, ir, games)\n",
    "    save_model(model, imputer, scaler, seeds, col, gb, ir, \"/app/MarchMadness/Kaggle-March-Madness-Prediction/ModelPath/tournament_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
